{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data from csv files. We store the data in different ways so that we can grab them immediately for different situation. Also we're transforming them into torch dataloaders for further uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from utils import index_til_exceed\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = pd.read_csv(\"./train_X_origin.csv\").set_index('ID')\n",
    "dfY = pd.read_csv(\"./train_Y.csv\").set_index(\"ID\")\n",
    "dfTest = pd.read_csv(\"./test_X.csv\", sep=\";\")\n",
    "dfFormat = pd.read_csv(\"./format.csv\").set_index(\"ID\")\n",
    "trainX_df = dfX.loc[dfX[\"DATASET\"] < 4]\n",
    "valX_df = dfX.loc[dfX[\"DATASET\"] == 4]\n",
    "trainY_df = dfY.loc[dfY[\"DATASET\"] < 4]\n",
    "valY_df = dfY.loc[dfY[\"DATASET\"] == 4]\n",
    "dfData = pd.read_csv(\"./train_X.csv\", sep=\";\")\n",
    "data = dfData.to_numpy()[:, 2:]\n",
    "data_test = dfTest.to_numpy()[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prediction_reshape\n",
    "def metric(target, pred):\n",
    "    target_means = np.array([row.mean() for row in target.reshape(-1, 16)])\n",
    "    pred_means, pred_variances = prediction_reshape(pred.reshape(-1, 16))\n",
    "    pred_means_np = np.array(pred_means)\n",
    "    pred_variances_np = np.array(pred_variances)\n",
    "    nline = len(pred_means)\n",
    "\n",
    "    chi2 = (pred_means_np-target_means)**2\n",
    "        \n",
    "    R2 = np.sum(chi2)/np.sum((target_means)**2)\n",
    "    RELIABILITY = np.sqrt(np.mean(chi2/(pred_variances_np+10-9)))\n",
    "\n",
    "    score=-(np.log(R2)+abs(np.log(RELIABILITY)))\n",
    "    is_higher_better = True\n",
    "    return \"climate_metric\", score, is_higher_better\n",
    "\n",
    "\n",
    "from utils import prediction_reshape\n",
    "from climate_challenge_custom_metric import climate_metric_function\n",
    "def score_pred(aa, label):\n",
    "    means, variances = prediction_reshape(aa.reshape(-1, 16))\n",
    "    pred = pd.DataFrame({\"MEAN\":means, \"VARIANCE\":variances})\n",
    "    score_pred = climate_metric_function(label, pred)\n",
    "    return score_pred\n",
    "\n",
    "#print(score_pred(predY, valY_df))\n",
    "#testY = gbm.predict(testX_np_transformed, num_iterations = gbm.best_iteration)\n",
    "def test_submit(aa, name):\n",
    "    means, variances = prediction_reshape(aa.reshape(-1, 16))\n",
    "    df = dfFormat\n",
    "    df[\"MEAN\"] = means\n",
    "    df[\"VARIANCE\"] = variances\n",
    "    df.to_csv(f'./submissions/pred_{name}.csv', index = True)\n",
    "    print(\"Prediction saved...\")\n",
    "\n",
    "def index_from_MY(M, Y):\n",
    "    if M > 0:\n",
    "        return (M-1)*11+Y+10\n",
    "    else:\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_shuffle = data.reshape(-1, 16, 255)\n",
    "perm = np.random.permutation(len(data_to_shuffle[:,0,0]))\n",
    "# print(perm[:10])\n",
    "data_shuffled = data_to_shuffle[perm, :, :].reshape(-1, 255)\n",
    "trainX_np = data[:12288, :254]\n",
    "valX_np = data[12288:, :254]\n",
    "allX_np = data[:, :254]\n",
    "trainY_np = data[:12288, -1]\n",
    "valY_np = data[12288:, -1]\n",
    "allY_np = data[:, -1]\n",
    "testX_np = data_test[:, :254]\n",
    "trainX_np_shuffled = data_shuffled[:12288, :254]\n",
    "valX_np_shuffled = data_shuffled[12288:, :254]\n",
    "allX_np_shuffled = data_shuffled[:, :254]\n",
    "trainY_np_shuffled = data_shuffled[:12288, -1]\n",
    "valY_np_shuffled = data_shuffled[12288:, -1]\n",
    "allY_np_shuffled = data_shuffled[:, -1]\n",
    "trainY_df_shuffled, _ = prediction_reshape(trainY_np_shuffled.reshape(-1, 16))\n",
    "trainY_df_shuffled = pd.DataFrame({\"MEAN\":trainY_df_shuffled, \"VARIANCE\": [np.nan]*len(trainY_df_shuffled)})\n",
    "valY_df_shuffled, _ = prediction_reshape(valY_np_shuffled.reshape(-1, 16))\n",
    "valY_df_shuffled = pd.DataFrame({\"MEAN\":valY_df_shuffled, \"VARIANCE\": [np.nan]*len(valY_df_shuffled)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing by normalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler().fit(trainX_np)\n",
    "trainX_np_normalized = sc.transform(trainX_np)\n",
    "valX_np_normalized = sc.transform(valX_np)\n",
    "testX_np_normalized = sc.transform(testX_np)\n",
    "\n",
    "sc_shuffled = StandardScaler().fit(trainX_np_shuffled)\n",
    "trainX_np_shuffled_normalized = sc_shuffled.transform(trainX_np_shuffled)\n",
    "valX_np_shuffled_normalized = sc_shuffled.transform(valX_np_shuffled)\n",
    "testX_np_shuffled_normalized = sc_shuffled.transform(testX_np)\n",
    "\n",
    "sc_all = StandardScaler().fit(allX_np)\n",
    "allX_np_normalized = sc_all.transform(allX_np)\n",
    "allX_np_shuffled_normalized = sc_all.transform(allX_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors for DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = torch.from_numpy(trainX_np_shuffled_normalized).to(\"cuda\").float()\n",
    "valX = torch.from_numpy(valX_np_shuffled_normalized).to(\"cuda\").float()\n",
    "valY = torch.from_numpy(valY_np_shuffled).to(\"cuda\").float().unsqueeze(1)\n",
    "trainY = torch.from_numpy(trainY_np_shuffled).to(\"cuda\").float().unsqueeze(1)\n",
    "testX = torch.from_numpy(testX_np_shuffled_normalized).to(\"cuda\").float()\n",
    "\n",
    "train_data= TensorDataset(trainX, trainY)\n",
    "val_data = TensorDataset(valX, valY)\n",
    "train_data_recent = TensorDataset(trainX[:, :10], trainY)\n",
    "val_data_recent = TensorDataset(trainX[:, :10], trainY)\n",
    "train_loader = DataLoader(train_data, batch_size = 64, shuffle = True)\n",
    "val_loader = DataLoader(val_data, batch_size = 64, shuffle = True)\n",
    "train_loader_recent = DataLoader(train_data_recent, batch_size = 64, shuffle = True)\n",
    "val_loader_recent = DataLoader(val_data_recent, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Benchmark:  -1.3277852269792563\n",
      "Validation Benchmark:  -1.5995618725175895\n",
      "Training Benchmark with shuffling:  -1.2794413320272424\n",
      "Validation Benchmark with shuffling:  -1.6573494562835753\n"
     ]
    }
   ],
   "source": [
    "pred_train_benchmark = trainX_np[:, 9]\n",
    "pred_val_benchmark = valX_np[:, 9]\n",
    "pred_train_shuffle_benchmark = trainX_np_shuffled[:, 9]\n",
    "pred_val_shuffle_benchmark = valX_np_shuffled[:, 9]\n",
    "print(\"Training Benchmark: \", score_pred(pred_train_benchmark, trainY_df))\n",
    "print(\"Validation Benchmark: \", score_pred(pred_val_benchmark, valY_df))\n",
    "print(\"Training Benchmark with shuffling: \", score_pred(pred_train_shuffle_benchmark, trainY_df_shuffled))\n",
    "print(\"Validation Benchmark with shuffling: \", score_pred(pred_val_shuffle_benchmark, valY_df_shuffled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple calculation of the means to see how the variables behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with best performance in training: [18 22  1  5  4 19 17  0  8], with score: [-1.3341052649073424, -1.3209518134161182, -1.2844178515599305, -1.2810905181103258, -1.2771765719246786, -1.2696471507895244, -1.2420247202966577, -1.2151217334725608, -1.1699814856878423]\n",
      "Model with best performance in validation: [16  0 15  2  7  1  6 12  5], with score: [-1.6252185680986158, -1.59131339975462, -1.5809363122508637, -1.5499614770633192, -1.5357665697752658, -1.5126760479533694, -1.4594159032882577, -1.4445212854216318, -1.4351372473711352]\n",
      "Model with best performance in training with shuffling: [19  2 22  6 17  1  5  0  8],  with score: [-1.3702341304678156, -1.3701694375292188, -1.3607430436644454, -1.35832331017058, -1.3072426748035908, -1.2959473042146146, -1.295082118020785, -1.262094917723523, -1.2558747813228073]\n",
      "Model with best performance in validation with shuffling: [19 22  1  4 17  5 18  0  8],  with score: [-1.4343846782025356, -1.429951151917416, -1.4275019155405473, -1.416057834362891, -1.4153527034169442, -1.3735318199685111, -1.3365769091782695, -1.3253024705930927, -1.2804537121447286]\n",
      "Prediction saved...\n"
     ]
    }
   ],
   "source": [
    "res_train = [np.array([0.0]*12288) for k in range(23)]\n",
    "res_train_shuffle = [np.array([0.0]*12288) for k in range(23)]\n",
    "res_val = [np.array([0.0]*3072) for k in range(23)]\n",
    "res_val_shuffle = [np.array([0.0]*3072) for k in range(23)]\n",
    "index = 0\n",
    "for k in range(23):\n",
    "    if k == 0:\n",
    "        j = 10\n",
    "    else:\n",
    "        j = 11\n",
    "    for i in range(j):\n",
    "        res_train[k]+=trainX_np[:, index]/10\n",
    "        res_val[k]+=valX_np[:, index]/10\n",
    "        res_train_shuffle[k]+=trainX_np_shuffled[:, index]/10\n",
    "        res_val_shuffle[k]+=valX_np_shuffled[:, index]/10\n",
    "        index+=1\n",
    "best_model_train = np.argsort([score_pred(res_train[k], trainY_df) for k in range(23)])[-9:]\n",
    "best_model_val = np.argsort([score_pred(res_val[k], valY_df) for k in range(23)])[-9:]\n",
    "best_model_train_shuffle = np.argsort([score_pred(res_train_shuffle[k], trainY_df_shuffled) for k in range(23)])[-9:]\n",
    "best_model_val_shuffle= np.argsort([score_pred(res_val_shuffle[k], valY_df_shuffled) for k in range(23)])[-9:]\n",
    "print(f\"Model with best performance in training: {best_model_train},\",\n",
    " f\"with score: {[score_pred(res_train[k], trainY_df) for k in best_model_train]}\")\n",
    "print(f\"Model with best performance in validation: {best_model_val},\",\n",
    " f\"with score: {[score_pred(res_val[k], valY_df) for k in best_model_val]}\")\n",
    "print(f\"Model with best performance in training with shuffling: {best_model_train_shuffle},\", \n",
    "f\" with score: {[score_pred(res_train_shuffle[k], trainY_df_shuffled) for k in best_model_train_shuffle]}\")\n",
    "print(f\"Model with best performance in validation with shuffling: {best_model_val_shuffle},\",\n",
    " f\" with score: {[score_pred(res_val_shuffle[k], valY_df_shuffled) for k in best_model_val_shuffle]}\")\n",
    "res_test = np.array([0.0]*3072*2)\n",
    "for k in range(11):\n",
    "    if k<10:\n",
    "        res_test+=(testX_np[:, index_from_MY(8,k)]+testX_np[:, index_from_MY(5, k)]+testX_np[:, index_from_MY(0, k)])/32\n",
    "    else:\n",
    "        res_test+=(testX_np[:, index_from_MY(8, k)]+testX_np[:, index_from_MY(5, k)])/32\n",
    "test_submit(res_test, \"MeansOverBestModelAndObservations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "[18 19  6 22 17  1  5  0  8]\n",
      "Round 1\n",
      "[ 6 18 19 22 17  1  5  0  8]\n",
      "Round 2\n",
      "[ 4 18 19 22 17  1  5  0  8]\n",
      "Round 3\n",
      "[ 6  4 22 18 17  1  5  0  8]\n",
      "Round 4\n",
      "[19  4 18 22 17  1  5  0  8]\n",
      "Round 5\n",
      "[ 4 22 18 19 17  1  5  0  8]\n",
      "Round 6\n",
      "[18  6 19 22 17  1  5  0  8]\n",
      "Round 7\n",
      "[ 4  6 19 22  1 17  5  0  8]\n",
      "Round 8\n",
      "[18 19  6 22 17  1  5  0  8]\n",
      "Round 9\n",
      "[18  4 22 19 17  1  5  8  0]\n"
     ]
    }
   ],
   "source": [
    "round = 10\n",
    "def test_for_best_model(round):\n",
    "    ll = np.array([0]*23)\n",
    "    for k in range(round):\n",
    "        perm = np.random.permutation(len(data_to_shuffle[:,0,0]))\n",
    "        data_shuffled = data_to_shuffle[perm, :, :].reshape(-1, 255)\n",
    "        trainX_np_shuffled_testing = data_shuffled[:12288, :254]\n",
    "        valX_np_shuffled_testing = data_shuffled[12288:, :254]\n",
    "        trainY_np_shuffled_testing = data_shuffled[:12288, -1]\n",
    "        valY_np_shuffled_testing = data_shuffled[12288:, -1]\n",
    "        trainY_df_shuffled_testing, _ = prediction_reshape(trainY_np_shuffled_testing.reshape(-1, 16))\n",
    "        trainY_df_shuffled_testing = pd.DataFrame({\"MEAN\":trainY_df_shuffled_testing, \"VARIANCE\": [np.nan]*len(trainY_df_shuffled_testing)})\n",
    "        valY_df_shuffled_testing, _ = prediction_reshape(valY_np_shuffled_testing.reshape(-1, 16))\n",
    "        valY_df_shuffled_testing = pd.DataFrame({\"MEAN\":valY_df_shuffled_testing, \"VARIANCE\": [np.nan]*len(valY_df_shuffled_testing)})\n",
    "        res_train = [np.array([0.0]*12288) for k in range(23)]\n",
    "        res_val = [np.array([0.0]*3072) for k in range(23)]\n",
    "        index = 0\n",
    "        for k in range(23):\n",
    "            if k == 0:\n",
    "                j = 10\n",
    "            else:\n",
    "                j = 11\n",
    "            for i in range(j):\n",
    "                res_train[k]+=trainX_np_shuffled_testing[:, index]/10\n",
    "                res_val[k]+=valX_np_shuffled_testing[:, index]/10\n",
    "                index+=1\n",
    "        model_ranking_train_list = np.argsort([score_pred(res_train[k], trainY_df_shuffled_testing) for k in range(23)])\n",
    "        model_ranking_val_list = np.argsort([score_pred(res_val[k], valY_df_shuffled_testing) for k in range(23)])\n",
    "        for k in range(len(model_ranking_train_list)):\n",
    "            ll[model_ranking_train_list[k]]+=k\n",
    "        # for k in range(len(model_ranking_val_list)):\n",
    "        #     ll[model_ranking_val_list[k]]+=k\n",
    "    indices = np.argsort(ll)[-9:]\n",
    "    # plt.title('Best Model Ranking')\n",
    "    # plt.barh(range(len(indices)), ll[indices], color='b', align='center')\n",
    "    # plt.yticks(range(len(indices)), [i for i in indices])\n",
    "    # plt.xlabel('Ranking')\n",
    "    # plt.show()\n",
    "    return ll\n",
    "for k in range(10):\n",
    "    print(f\"Round {k}\")\n",
    "    print(np.argsort(test_for_best_model(round))[-9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  -1.04054592581554\n",
      "Validation score:  -1.414768156451494\n",
      "Training score with shuffling:  -1.085766734500794\n",
      "Validation score with shuffling:  -1.1572345529948167\n",
      "Prediction saved...\n"
     ]
    }
   ],
   "source": [
    "res_train_mean = np.array([0.0]*12288)\n",
    "res_train_mean_shuffle = np.array([0.0]*12288)\n",
    "res_val_mean = np.array([0.0]*3072)\n",
    "res_val_mean_shuffle = np.array([0.0]*3072)\n",
    "res_test_mean = np.array([0.0]*3072*2)\n",
    "best_models_indices = [0, 8, 5, 1, 17, 22]\n",
    "for k in range(11):\n",
    "    if k<10:\n",
    "        for i in best_models_indices:\n",
    "            res_train_mean += trainX_np[:, index_from_MY(i, k)]/(len(best_models_indices)*11-1)\n",
    "            res_train_mean_shuffle += trainX_np_shuffled[:, index_from_MY(i, k)]/(len(best_models_indices)*11-1)\n",
    "            res_val_mean += valX_np[:, index_from_MY(i, k)]/(len(best_models_indices)*11-1)\n",
    "            res_val_mean_shuffle += valX_np_shuffled[:, index_from_MY(i, k)]/(len(best_models_indices)*11-1)\n",
    "            res_test_mean += testX_np[:, index_from_MY(i, k)]/(len(best_models_indices)*11-1)\n",
    "    else:\n",
    "        for i in best_models_indices:\n",
    "            if i > 0:\n",
    "                res_train_mean += trainX_np[:, index_from_MY(i, k)]/(len(best_models_indices)*11-1)\n",
    "                res_train_mean_shuffle += trainX_np_shuffled[:, index_from_MY(i, k)]/(len(best_models_indices)*11-1)\n",
    "                res_val_mean += valX_np[:, index_from_MY(i, k)]/(len(best_models_indices)*11-1)\n",
    "                res_val_mean_shuffle += valX_np_shuffled[:, index_from_MY(i, k)]/(len(best_models_indices)*11-1)\n",
    "                res_test_mean += testX_np[:, index_from_MY(i, k)]/(len(best_models_indices)*11-1)\n",
    "print(\"Training score: \", score_pred(res_train_mean, trainY_df))\n",
    "print(\"Validation score: \", score_pred(res_val_mean, valY_df))\n",
    "print(\"Training score with shuffling: \", score_pred(res_train_mean_shuffle, trainY_df_shuffled))\n",
    "print(\"Validation score with shuffling: \", score_pred(res_val_mean_shuffle, valY_df_shuffled))\n",
    "test_submit(res_test_mean, \"MEANWithBestModels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple calculation of the mean of the predictions of all the models (should do more or less well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  -1.197763000299892\n",
      "Valid score:  -1.460989971094912\n",
      "Training score with shuffling:  -1.2336097107202142\n",
      "Valid score with shuffling:  -1.2690486284708065\n",
      "Prediction saved...\n"
     ]
    }
   ],
   "source": [
    "mean_train_shuffled_predicted = np.array([0.0]*12288)\n",
    "mean_val_shuffled_predicted = np.array([0.0]*3072)\n",
    "mean_train_predicted = np.array([0.0]*12288)\n",
    "mean_val_predicted = np.array([0.0]*3072)\n",
    "mean_test_predicted = np.array([0.0]*6144)\n",
    "for k in range(1, 23):\n",
    "    mean_train_shuffled_predicted += trainX_np_shuffled[:, 9+11*k]/22\n",
    "    mean_val_shuffled_predicted += valX_np_shuffled[:, 9+11*k]/22\n",
    "    mean_train_predicted += trainX_np[:, 9+11*k]/22\n",
    "    mean_val_predicted += valX_np[:, 9+11*k]/22\n",
    "    mean_test_predicted+= testX_np[:, 9+11*k]/22\n",
    "print(\"Training score: \", score_pred(mean_train_predicted, trainY_df))\n",
    "print(\"Valid score: \", score_pred(mean_val_predicted, valY_df))\n",
    "print(\"Training score with shuffling: \", score_pred(mean_train_shuffled_predicted, trainY_df_shuffled))\n",
    "print(\"Valid score with shuffling: \", score_pred(mean_val_shuffled_predicted, valY_df_shuffled))\n",
    "test_submit(mean_test_predicted, \"MeansOfModelPrediction\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the dependancy of the variables and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "means_target_train, _ = prediction_reshape(trainY_np.reshape(-1, 16))\n",
    "means_target_train = np.array(means_target_train)\n",
    "for k in range(23):\n",
    "    means_train, variances_train = prediction_reshape(res_train[k].reshape(-1, 16))\n",
    "    means_train = np.array(means_train)\n",
    "    diff = np.abs(means_train-means_target_train)\n",
    "    plt.hist(x=diff, bins='auto', alpha=0.7, rwidth=0.9)\n",
    "    plt.savefig(f\"./plots/hist_model_mean{k}.png\")\n",
    "    print(f\"hist_model_mean{k} saved\")\n",
    "    plt.clf()\n",
    "    plt.scatter(means_train, means_target_train, alpha = 0.1)\n",
    "    plt.savefig(f\"./plots/scatter_model_mean{k}.png\")\n",
    "    print(f\"scatter_model_mean{k} saved\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After plotting the dependency between the variables and the target, we do some feature selection and dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we restrain ourself to the models that perform better with only the means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97]\n"
     ]
    }
   ],
   "source": [
    "best_indices = []\n",
    "for m in sorted(best_models_indices[:3]):\n",
    "    if m > 0:\n",
    "        j = 11\n",
    "    else:\n",
    "        j = 10\n",
    "    for k in range(j):\n",
    "        best_indices.append(index_from_MY(m, k))\n",
    "print(best_indices)\n",
    "trainX_np_normalized_best = trainX_np_normalized[:, best_indices]\n",
    "valX_np_normalized_best = valX_np_normalized[:, best_indices]\n",
    "trainX_np_shuffled_normalized_best = trainX_np_shuffled_normalized[:, best_indices]\n",
    "valX_np_shuffled_normalized_best = valX_np_shuffled_normalized[:, best_indices]\n",
    "allX_np_normalized_best = allX_np_normalized[:, best_indices]\n",
    "allX_np_shuffled_normalized_best = allX_np_shuffled_normalized[:, best_indices]\n",
    "testX_np_normalized_best = testX_np_normalized[:, best_indices]\n",
    "testX_np_shuffled_normalized_best = testX_np_shuffled_normalized[:, best_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 254 features.\n",
      "Fitting estimator with 253 features.\n",
      "Fitting estimator with 252 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 250 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 248 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 245 features.\n",
      "Fitting estimator with 244 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 242 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 240 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 238 features.\n",
      "Fitting estimator with 237 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 233 features.\n",
      "Fitting estimator with 232 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 230 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 225 features.\n",
      "Fitting estimator with 224 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 220 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 217 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 212 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 210 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 208 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 205 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 202 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 200 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 198 features.\n",
      "Fitting estimator with 197 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 194 features.\n",
      "Fitting estimator with 193 features.\n",
      "Fitting estimator with 192 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 190 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 188 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=LinearRegression(), n_features_to_select=10, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=LinearRegression(), n_features_to_select=10, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=LinearRegression(), n_features_to_select=10, verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_RFE = RFE(\n",
    "    LinearRegression(),\n",
    "    n_features_to_select=10,\n",
    "    verbose=1,\n",
    ")\n",
    "selector_RFE.fit(trainX_np_shuffled_normalized, trainY_np_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False  True  True False False False  True False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True  True False  True  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False]\n"
     ]
    }
   ],
   "source": [
    "print(selector_RFE.support_)\n",
    "trainX_np_shuffled_selected = selector_RFE.transform(trainX_np_shuffled_normalized)\n",
    "valX_np_shuffled_selected = selector_RFE.transform(valX_np_shuffled_normalized)\n",
    "testX_np_selected = selector_RFE.transform(testX_np_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=10, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10, random_state=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(random_state = 1, max_depth=10)\n",
    "model_rf.fit(trainX_np_normalized, trainY_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m importances \u001b[39m=\u001b[39m model_rf\u001b[39m.\u001b[39mfeature_importances_\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(importances)\n\u001b[0;32m      3\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(importances)[\u001b[39m-\u001b[39m\u001b[39m9\u001b[39m:]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_rf' is not defined"
     ]
    }
   ],
   "source": [
    "importances = model_rf.feature_importances_\n",
    "print(importances)\n",
    "indices = np.argsort(importances)[-9:]\n",
    "features = dfData.drop([\"POS\", \"DATA\", \"Y\"], axis = \"columns\").columns\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionaly reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[0.09128919 0.0598804  0.04586726 0.04156713 0.03532029 0.03212401\n",
      " 0.03002951 0.02733157 0.02509556 0.02368212]\n",
      "10\n",
      "32 7\n",
      "32 8\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=254)\n",
    "pca.fit(trainX_np_normalized)\n",
    "#num_components = index_til_exceed(pca.explained_variance_ratio_, 0.81)+1\n",
    "num_components = 10\n",
    "print(num_components)\n",
    "pca = PCA(n_components = num_components)\n",
    "pca.fit(trainX_np_normalized)\n",
    "print(pca.explained_variance_ratio_[:10])\n",
    "\n",
    "trainX_np_transformed = pca.transform(trainX_np_normalized)\n",
    "testX_np_transformed = pca.transform(testX_np_normalized)\n",
    "valX_np_transformed = pca.transform(valX_np_normalized)\n",
    "\n",
    "pca_shuffle = PCA(n_components=254)\n",
    "pca.fit(trainX_np_shuffled_normalized)\n",
    "#num_components_shuffle = index_til_exceed(pca.explained_variance_ratio_, 0.81)+1\n",
    "num_components_shuffle = 10\n",
    "print(num_components_shuffle)\n",
    "pca_shuffle = PCA(n_components = num_components_shuffle)\n",
    "pca.fit(trainX_np_shuffled_normalized)\n",
    "trainX_np_shuffled_transformed = pca.transform(trainX_np_shuffled_normalized)\n",
    "testX_np_shuffled_transformed = pca.transform(testX_np_shuffled_normalized)\n",
    "valX_np_shuffled_transformed = pca.transform(valX_np_shuffled_normalized)\n",
    "\n",
    "pca_all = PCA(n_components=20)\n",
    "pca_all.fit(allX_np_normalized)\n",
    "allX_np_transformed = pca_all.transform(allX_np_normalized)\n",
    "\n",
    "pca_best = PCA()\n",
    "pca_best.fit(trainX_np_normalized_best)\n",
    "num_components_best = index_til_exceed(pca_best.explained_variance_ratio_, 0.81)+1\n",
    "print(len(pca_best.explained_variance_ratio_), num_components_best)\n",
    "pca_best = PCA(n_components=num_components_best)\n",
    "pca_best.fit(trainX_np_normalized_best)\n",
    "trainX_np_transformed_best = pca_best.transform(trainX_np_normalized_best)\n",
    "testX_np_transformed_best = pca_best.transform(testX_np_normalized_best)\n",
    "valX_np_transformed_best = pca_best.transform(valX_np_normalized_best)\n",
    "\n",
    "pca_best_shuffle = PCA()\n",
    "pca_best_shuffle.fit(trainX_np_shuffled_normalized_best)\n",
    "num_components_best_shuffle = index_til_exceed(pca_best_shuffle.explained_variance_ratio_, 0.81)+1\n",
    "print(len(pca_best_shuffle.explained_variance_ratio_), num_components_best_shuffle)\n",
    "pca_best_shuffle = PCA(n_components=num_components_best_shuffle)\n",
    "pca_best_shuffle.fit(trainX_np_shuffled_normalized_best)\n",
    "trainX_np_shuffled_transformed_best = pca_best_shuffle.transform(trainX_np_shuffled_normalized_best)\n",
    "testX_np_shuffled_transformed_best = pca_best_shuffle.transform(testX_np_shuffled_normalized_best)\n",
    "valX_np_shuffled_transformed_best = pca_best_shuffle.transform(valX_np_shuffled_normalized_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start the part of using different models in ML to get a better result than using just the means of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0016202538913725\n",
      "-1.5278940367416713\n",
      "-1.0804195095703328\n",
      "-1.0848235088516134\n",
      "Prediction saved...\n",
      "Prediction saved...\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(trainX_np[:, :10], trainY_np)\n",
    "pred_train_LR = reg.predict(trainX_np[:, :10])\n",
    "print(score_pred(pred_train_LR, trainY_df))\n",
    "pred_val_LR = reg.predict(valX_np[:, :10])\n",
    "print(score_pred(pred_val_LR, valY_df))\n",
    "reg_shuffle = LinearRegression().fit(trainX_np_shuffled[:, :10], trainY_np_shuffled)\n",
    "pred_train_shuffle_LR = reg_shuffle.predict(trainX_np_shuffled[:, :10])\n",
    "print(score_pred(pred_train_shuffle_LR, trainY_df_shuffled))\n",
    "pred_val_shuffle_LR = reg_shuffle.predict(valX_np_shuffled[:, :10])\n",
    "print(score_pred(pred_val_shuffle_LR, valY_df_shuffled))\n",
    "\n",
    "pred_test_LR = reg.predict(testX_np[:, :10])\n",
    "test_submit(pred_test_LR, \"LRAllObservation\")\n",
    "pred_test_shuffle_LR = reg_shuffle.predict(testX_np[:, :10])\n",
    "test_submit(pred_test_shuffle_LR, \"LRAllObservationShuffled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  -1.020952329667872\n",
      "Validation score:  -1.5450669182148626\n",
      "Training score with shuffling:  -1.1037777708851229\n",
      "Validation score with shuffling:  -1.1143276339536863\n",
      "Prediction saved...\n",
      "Prediction saved...\n"
     ]
    }
   ],
   "source": [
    "model_index = 9+(best_model_train-1)*11\n",
    "reg_best_model = LinearRegression().fit(trainX_np[:, (model_index+1):(model_index+12)], trainY_np)\n",
    "pred_train_LR_best_model = reg_best_model.predict(trainX_np[:, (model_index+1):(model_index+12)])\n",
    "print(\"Training score: \", score_pred(pred_train_LR_best_model, trainY_df))\n",
    "pred_val_LR_best_model = reg_best_model.predict(valX_np[:, (model_index+1):(model_index+12)])\n",
    "print(\"Validation score: \", score_pred(pred_val_LR_best_model, valY_df))\n",
    "\n",
    "\n",
    "model_index_shuffle = 9 +(best_model_train_shuffle-1)*11\n",
    "reg_best_model_shuffle = LinearRegression().fit(trainX_np_shuffled[:, (model_index_shuffle+1):(model_index_shuffle+12)], trainY_np_shuffled)\n",
    "pred_train_shuffle_LR_best_model = reg_best_model_shuffle.predict(trainX_np_shuffled[:, (model_index_shuffle+1):(model_index_shuffle+12)])\n",
    "print(\"Training score with shuffling: \", score_pred(pred_train_shuffle_LR_best_model, trainY_df_shuffled))\n",
    "pred_val_shuffle_LR_best_model = reg_best_model_shuffle.predict(valX_np_shuffled[:, (model_index_shuffle+1):(model_index_shuffle+12)])\n",
    "print(\"Validation score with shuffling: \", score_pred(pred_val_shuffle_LR_best_model, valY_df_shuffled))\n",
    "\n",
    "\n",
    "pred_test_LR_best_model = reg_best_model.predict(testX_np[:, (model_index+1):(model_index+12)])\n",
    "pred_test_shuffle_LR_best_model = reg_best_model_shuffle.predict(testX_np[:, (model_index_shuffle+1):(model_index_shuffle+12)])\n",
    "test_submit(pred_test_LR_best_model, \"LRWithBestModelInMeans\")\n",
    "test_submit(pred_test_shuffle_LR_best_model, \"LRWithBestModelInMeansShuffled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Last Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.5205237305160313\n",
      "Prediction saved...\n"
     ]
    }
   ],
   "source": [
    "reg2 = LinearRegression().fit(trainX_np[:, 9].reshape(-1, 1), trainY_np)\n",
    "print()\n",
    "pred_val_LR2 = reg2.predict(valX_np[:, 9].reshape(-1, 1))\n",
    "print(score_pred(pred_val_LR2, valY_df))\n",
    "pred_test_LR2 = reg2.predict(testX_np[:, 9].reshape(-1,1))\n",
    "test_submit(pred_test_LR2, \"LRLastObservation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.053835342596043\n",
      "-1.0094850741415642\n",
      "Prediction saved...\n"
     ]
    }
   ],
   "source": [
    "lr_RFE = LinearRegression().fit(trainX_np_shuffled_selected, trainY_np_shuffled)\n",
    "pred_train_LR2 = lr_RFE.predict(trainX_np_shuffled_selected)\n",
    "print(score_pred(pred_train_LR2, trainY_df_shuffled))\n",
    "pred_val_LR2 = lr_RFE.predict(valX_np_shuffled_selected)\n",
    "print(score_pred(pred_val_LR2, valY_df_shuffled))\n",
    "pred_test_LR2 = lr_RFE.predict(testX_np_selected)\n",
    "test_submit(pred_test_LR2, \"LR10coodSelectedByNFE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.199635749297854\n",
      "-1.631707772407675\n"
     ]
    }
   ],
   "source": [
    "lr_PCA = LinearRegression().fit(trainX_np_shuffled_transformed, trainY_np_shuffled)\n",
    "pred_train_LR_PCA = lr_PCA.predict(trainX_np_shuffled_transformed)\n",
    "print(score_pred(pred_train_LR_PCA, trainY_df))\n",
    "pred_val_LR_PCA = lr_PCA.predict(valX_np_shuffled_transformed)\n",
    "print(score_pred(pred_val_LR_PCA, valY_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With best models and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  -0.9657615423778054\n",
      "Validation score:  -1.4926287339354798\n",
      "Training score with shuffling:  -1.0402980769626395\n",
      "Training score with shuffling:  -1.0460009898659692\n"
     ]
    }
   ],
   "source": [
    "lr_PCA_best = LinearRegression().fit(trainX_np_transformed_best, trainY_np)\n",
    "pred_train_LR_PCA_best = lr_PCA_best.predict(trainX_np_transformed_best)\n",
    "print(\"Training score: \", score_pred(pred_train_LR_PCA_best, trainY_df))\n",
    "pred_val_LR_PCA_best = lr_PCA_best.predict(valX_np_transformed_best)\n",
    "print(\"Validation score: \", score_pred(pred_val_LR_PCA_best, valY_df))\n",
    "\n",
    "lr_PCA_best_shuffle = LinearRegression().fit(trainX_np_shuffled_transformed_best, trainY_np_shuffled)\n",
    "pred_train_LR_PCA_best_shuffle=  lr_PCA_best_shuffle.predict(trainX_np_shuffled_transformed_best)\n",
    "print(\"Training score with shuffling: \", score_pred(pred_train_LR_PCA_best_shuffle, trainY_df_shuffled))\n",
    "pred_val_LR_PCA_best_shuffle=  lr_PCA_best_shuffle.predict(valX_np_shuffled_transformed_best)\n",
    "print(\"Training score with shuffling: \", score_pred(pred_val_LR_PCA_best_shuffle, valY_df_shuffled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction saved...\n",
      "Prediction saved...\n"
     ]
    }
   ],
   "source": [
    "pred_test_LR_PCA_best = lr_PCA_best.predict(testX_np_transformed_best)\n",
    "pred_test_LR_PCA_best_shuffle = lr_PCA_best_shuffle.predict(testX_np_shuffled_transformed_best)\n",
    "test_submit(pred_test_LR_PCA_best, \"LRBestModelsWithPCA\")\n",
    "test_submit(pred_test_LR_PCA_best_shuffle, \"LRBestModelsWithPCAWithShuffling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we try with Light GBM (faster version of Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Optuna for optimizing the hyperparameters in the LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(trainX_np_shuffled_normalized_best, trainY_np_shuffled)\n",
    "lgb_eval = lgb.Dataset(valX_np_shuffled_normalized_best, valY_np_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-23 18:59:13,227]\u001b[0m A new study created in memory with name: no-name-a795ae6c-a603-4827-886e-b1ecd6470285\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 18:59:17,035]\u001b[0m Trial 0 finished with value: -0.7608422777867556 and parameters: {'lambda_l1': 4.3739968499729146e-08, 'lambda_l2': 4.319102014393532e-06, 'num_leaves': 2880, 'feature_fraction': 0.601270304584327, 'bagging_fraction': 0.7915044657531347, 'bagging_freq': 3, 'learning_rate': 0.1887549522894483}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 18:59:20,549]\u001b[0m Trial 1 finished with value: -0.8940476658510765 and parameters: {'lambda_l1': 0.08075410227583978, 'lambda_l2': 1.1336773292068506e-06, 'num_leaves': 1380, 'feature_fraction': 0.6869870785874264, 'bagging_fraction': 0.8481839527716919, 'bagging_freq': 1, 'learning_rate': 0.015713628421081496}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 18:59:24,771]\u001b[0m Trial 2 finished with value: -0.784690788269442 and parameters: {'lambda_l1': 2.231089422815946e-07, 'lambda_l2': 2.954659152378146e-05, 'num_leaves': 1180, 'feature_fraction': 0.7105787309570515, 'bagging_fraction': 0.8664629044778857, 'bagging_freq': 4, 'learning_rate': 0.09583623963223523}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 18:59:27,246]\u001b[0m Trial 3 finished with value: -0.7904184812690068 and parameters: {'lambda_l1': 0.006223314380876986, 'lambda_l2': 5.816876659708817e-07, 'num_leaves': 2120, 'feature_fraction': 0.5975523249297372, 'bagging_fraction': 0.5513338550609347, 'bagging_freq': 4, 'learning_rate': 0.1585602275646649}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 18:59:30,412]\u001b[0m Trial 4 finished with value: -0.7742361149398748 and parameters: {'lambda_l1': 0.007843980085434868, 'lambda_l2': 4.360615486476907e-05, 'num_leaves': 1900, 'feature_fraction': 0.8514954744266917, 'bagging_fraction': 0.5171426393820775, 'bagging_freq': 2, 'learning_rate': 0.18604184788933775}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 18:59:33,319]\u001b[0m Trial 5 finished with value: -0.7885969887557267 and parameters: {'lambda_l1': 0.0002047003421667953, 'lambda_l2': 0.00012818157413779967, 'num_leaves': 220, 'feature_fraction': 0.8823070864658809, 'bagging_fraction': 0.8714349561164267, 'bagging_freq': 7, 'learning_rate': 0.21612198586707468}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 18:59:36,868]\u001b[0m Trial 6 finished with value: -0.7903338476777989 and parameters: {'lambda_l1': 4.18383020397839e-06, 'lambda_l2': 1.3416922344538189e-08, 'num_leaves': 1740, 'feature_fraction': 0.5372487777885839, 'bagging_fraction': 0.4490810091970565, 'bagging_freq': 2, 'learning_rate': 0.09925887599271843}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 18:59:40,248]\u001b[0m Trial 7 finished with value: -0.7955515065269761 and parameters: {'lambda_l1': 0.4590595847084575, 'lambda_l2': 0.08840557603946564, 'num_leaves': 2180, 'feature_fraction': 0.5015169494448564, 'bagging_fraction': 0.9765722938498218, 'bagging_freq': 4, 'learning_rate': 0.23387318096751722}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 18:59:42,257]\u001b[0m Trial 8 finished with value: -0.8173107481677768 and parameters: {'lambda_l1': 2.6037902741940244, 'lambda_l2': 0.0013390534402874825, 'num_leaves': 1760, 'feature_fraction': 0.6960938122142236, 'bagging_fraction': 0.7394412858560913, 'bagging_freq': 5, 'learning_rate': 0.085026466422725}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 18:59:50,476]\u001b[0m Trial 9 finished with value: -0.810946817414797 and parameters: {'lambda_l1': 0.01907350332810824, 'lambda_l2': 0.011881063850580215, 'num_leaves': 2240, 'feature_fraction': 0.8455936359523328, 'bagging_fraction': 0.964464302775825, 'bagging_freq': 6, 'learning_rate': 0.16820564651031644}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 18:59:54,814]\u001b[0m Trial 10 finished with value: -0.7613946233119826 and parameters: {'lambda_l1': 1.4121201239278262e-08, 'lambda_l2': 6.394817409447885, 'num_leaves': 2960, 'feature_fraction': 0.43686960244663847, 'bagging_fraction': 0.6671808636415657, 'bagging_freq': 3, 'learning_rate': 0.29806008231226183}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 18:59:58,238]\u001b[0m Trial 11 finished with value: -0.7857207121646118 and parameters: {'lambda_l1': 1.2587202778260822e-08, 'lambda_l2': 7.884231676766814, 'num_leaves': 2780, 'feature_fraction': 0.40974170822263184, 'bagging_fraction': 0.660920983730116, 'bagging_freq': 3, 'learning_rate': 0.27936529565760065}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:00:02,925]\u001b[0m Trial 12 finished with value: -0.7884863884244777 and parameters: {'lambda_l1': 1.3018514149687991e-08, 'lambda_l2': 2.2154256060160233, 'num_leaves': 2940, 'feature_fraction': 0.4057526698949107, 'bagging_fraction': 0.681211747655346, 'bagging_freq': 3, 'learning_rate': 0.2802997962427509}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:00:10,335]\u001b[0m Trial 13 finished with value: -0.7776439063004137 and parameters: {'lambda_l1': 3.0022902891012707e-06, 'lambda_l2': 1.551701548382691e-06, 'num_leaves': 2620, 'feature_fraction': 0.5974801208778366, 'bagging_fraction': 0.7393412058926147, 'bagging_freq': 2, 'learning_rate': 0.298186490047923}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:00:14,397]\u001b[0m Trial 14 finished with value: -0.782718574947276 and parameters: {'lambda_l1': 9.430620671920063e-07, 'lambda_l2': 0.2273863011585163, 'num_leaves': 840, 'feature_fraction': 0.9970622698817011, 'bagging_fraction': 0.6046014498053492, 'bagging_freq': 3, 'learning_rate': 0.23801116635214445}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:00:19,741]\u001b[0m Trial 15 finished with value: -0.7861147811000742 and parameters: {'lambda_l1': 9.971466365108877e-05, 'lambda_l2': 0.0018934596318107527, 'num_leaves': 2540, 'feature_fraction': 0.4933530313643236, 'bagging_fraction': 0.7817328719582846, 'bagging_freq': 1, 'learning_rate': 0.20512014029196723}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:00:23,545]\u001b[0m Trial 16 finished with value: -0.7809760606806659 and parameters: {'lambda_l1': 1.0965200974220146e-07, 'lambda_l2': 4.614318646722196e-08, 'num_leaves': 2980, 'feature_fraction': 0.5940104416798293, 'bagging_fraction': 0.63412791967033, 'bagging_freq': 5, 'learning_rate': 0.12805001468499186}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:00:28,499]\u001b[0m Trial 17 finished with value: -0.8024448870575832 and parameters: {'lambda_l1': 1.871999875725545e-05, 'lambda_l2': 7.726430913944765e-06, 'num_leaves': 2460, 'feature_fraction': 0.46467245479145414, 'bagging_fraction': 0.803506333845067, 'bagging_freq': 5, 'learning_rate': 0.25904531532624325}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:00:31,600]\u001b[0m Trial 18 finished with value: -0.836990379952802 and parameters: {'lambda_l1': 1.053635626836536e-07, 'lambda_l2': 0.0005494851014253065, 'num_leaves': 340, 'feature_fraction': 0.7665331092937464, 'bagging_fraction': 0.584060564133608, 'bagging_freq': 3, 'learning_rate': 0.034415145948609074}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:00:34,995]\u001b[0m Trial 19 finished with value: -0.7859360953508543 and parameters: {'lambda_l1': 1.510004565201537e-08, 'lambda_l2': 0.028954398408533477, 'num_leaves': 2440, 'feature_fraction': 0.5558315761535965, 'bagging_fraction': 0.43173794827185696, 'bagging_freq': 2, 'learning_rate': 0.12801544343941423}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:00:40,068]\u001b[0m Trial 20 finished with value: -0.7906446407838711 and parameters: {'lambda_l1': 0.0009966337200141364, 'lambda_l2': 0.7565279238750583, 'num_leaves': 840, 'feature_fraction': 0.6562427323908714, 'bagging_fraction': 0.9129245150521854, 'bagging_freq': 6, 'learning_rate': 0.24908040637698706}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:00:43,143]\u001b[0m Trial 21 finished with value: -0.7673792411111156 and parameters: {'lambda_l1': 0.007014835232988646, 'lambda_l2': 4.0327645994347846e-05, 'num_leaves': 1880, 'feature_fraction': 0.794757458904889, 'bagging_fraction': 0.46897358483320073, 'bagging_freq': 2, 'learning_rate': 0.18229442650753838}. Best is trial 0 with value: -0.7608422777867556.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:00:47,032]\u001b[0m Trial 22 finished with value: -0.7377752933919968 and parameters: {'lambda_l1': 0.0023077719434512387, 'lambda_l2': 1.7480233081481513e-07, 'num_leaves': 3000, 'feature_fraction': 0.7886485535894862, 'bagging_fraction': 0.46644991789330914, 'bagging_freq': 1, 'learning_rate': 0.2023565800661427}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:00:50,859]\u001b[0m Trial 23 finished with value: -0.7751884178191318 and parameters: {'lambda_l1': 2.5606581082297848e-05, 'lambda_l2': 1.344620552245817e-07, 'num_leaves': 2780, 'feature_fraction': 0.771502745751314, 'bagging_fraction': 0.5072054538965751, 'bagging_freq': 1, 'learning_rate': 0.19732029853888958}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:00:59,483]\u001b[0m Trial 24 finished with value: -0.781884337383524 and parameters: {'lambda_l1': 0.0006590376054754812, 'lambda_l2': 1.6363234429714903e-07, 'num_leaves': 2960, 'feature_fraction': 0.9027972719224019, 'bagging_fraction': 0.7055802621486135, 'bagging_freq': 3, 'learning_rate': 0.13674006869805014}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:09,224]\u001b[0m Trial 25 finished with value: -0.7859138100984794 and parameters: {'lambda_l1': 2.9855737136311904e-07, 'lambda_l2': 4.206101979813901e-06, 'num_leaves': 2720, 'feature_fraction': 0.45036937443443914, 'bagging_fraction': 0.7878267697293407, 'bagging_freq': 1, 'learning_rate': 0.22097683006054314}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:12,115]\u001b[0m Trial 26 finished with value: -0.7831210845769069 and parameters: {'lambda_l1': 3.6172704278829006e-08, 'lambda_l2': 1.0528786240178124e-08, 'num_leaves': 2420, 'feature_fraction': 0.6477991496440942, 'bagging_fraction': 0.4001395236869113, 'bagging_freq': 4, 'learning_rate': 0.2702759424010977}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:17,173]\u001b[0m Trial 27 finished with value: -0.770056172445248 and parameters: {'lambda_l1': 1.0986217126858074e-06, 'lambda_l2': 5.680891673825705e-06, 'num_leaves': 2720, 'feature_fraction': 0.7518496103199863, 'bagging_fraction': 0.7280256203697677, 'bagging_freq': 2, 'learning_rate': 0.17649065384471413}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:23,629]\u001b[0m Trial 28 finished with value: -0.7704201359814428 and parameters: {'lambda_l1': 2.9810292870280976e-05, 'lambda_l2': 1.5222106621379696e-07, 'num_leaves': 2340, 'feature_fraction': 0.952516318972579, 'bagging_fraction': 0.6314469112636113, 'bagging_freq': 3, 'learning_rate': 0.2260130611873596}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:27,491]\u001b[0m Trial 29 finished with value: -0.8105907002025222 and parameters: {'lambda_l1': 0.13019603596149182, 'lambda_l2': 1.2523636898791187e-06, 'num_leaves': 1500, 'feature_fraction': 0.7265888261688269, 'bagging_fraction': 0.8310856458933843, 'bagging_freq': 1, 'learning_rate': 0.29783750515770857}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:30,369]\u001b[0m Trial 30 finished with value: -0.8061393919908728 and parameters: {'lambda_l1': 0.0024928963518691363, 'lambda_l2': 0.005897221352188036, 'num_leaves': 3000, 'feature_fraction': 0.6442678121243929, 'bagging_fraction': 0.5617224486107408, 'bagging_freq': 1, 'learning_rate': 0.04527554439524653}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:32,740]\u001b[0m Trial 31 finished with value: -0.7663003370035848 and parameters: {'lambda_l1': 0.03972055529452263, 'lambda_l2': 3.602356821486124e-05, 'num_leaves': 1320, 'feature_fraction': 0.8185511344550424, 'bagging_fraction': 0.49244671552103797, 'bagging_freq': 2, 'learning_rate': 0.14847831172182133}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:34,972]\u001b[0m Trial 32 finished with value: -0.7486029689143903 and parameters: {'lambda_l1': 0.08566378950597824, 'lambda_l2': 0.00011285027895281604, 'num_leaves': 1160, 'feature_fraction': 0.8146120788376504, 'bagging_fraction': 0.4857033843349111, 'bagging_freq': 2, 'learning_rate': 0.13868083837388634}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:35,497]\u001b[0m Trial 33 finished with value: -0.854917883236892 and parameters: {'lambda_l1': 8.952099296389695, 'lambda_l2': 0.0003018383087213556, 'num_leaves': 1000, 'feature_fraction': 0.7362230697642423, 'bagging_fraction': 0.5399885495827311, 'bagging_freq': 4, 'learning_rate': 0.11248897777618981}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:37,098]\u001b[0m Trial 34 finished with value: -0.799353131811728 and parameters: {'lambda_l1': 0.2602370050565221, 'lambda_l2': 4.527315078700126e-07, 'num_leaves': 960, 'feature_fraction': 0.8189849910674808, 'bagging_fraction': 0.40325199622070623, 'bagging_freq': 3, 'learning_rate': 0.07458819456300514}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:38,927]\u001b[0m Trial 35 finished with value: -0.7881541778865965 and parameters: {'lambda_l1': 1.0734022125745775, 'lambda_l2': 1.315903776001308e-05, 'num_leaves': 620, 'feature_fraction': 0.9040420438843075, 'bagging_fraction': 0.8955924501794339, 'bagging_freq': 2, 'learning_rate': 0.15775728464839692}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:41,027]\u001b[0m Trial 36 finished with value: -0.7703279695929848 and parameters: {'lambda_l1': 0.04464378725398896, 'lambda_l2': 0.00010666717785078864, 'num_leaves': 1260, 'feature_fraction': 0.6809445168046131, 'bagging_fraction': 0.4663735362727326, 'bagging_freq': 1, 'learning_rate': 0.19897526703533783}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:43,729]\u001b[0m Trial 37 finished with value: -0.7698508577199298 and parameters: {'lambda_l1': 0.0018986325676933174, 'lambda_l2': 3.0387704034609718e-06, 'num_leaves': 2080, 'feature_fraction': 0.8646788213490589, 'bagging_fraction': 0.5414848785994955, 'bagging_freq': 2, 'learning_rate': 0.10950616952052228}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:47,215]\u001b[0m Trial 38 finished with value: -0.7802433587090787 and parameters: {'lambda_l1': 0.0002598772252717655, 'lambda_l2': 0.00013823178028745598, 'num_leaves': 1560, 'feature_fraction': 0.5571158118825406, 'bagging_fraction': 0.8383421376950481, 'bagging_freq': 3, 'learning_rate': 0.14451053691826282}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:50,649]\u001b[0m Trial 39 finished with value: -0.7655629172239572 and parameters: {'lambda_l1': 0.014944640953723642, 'lambda_l2': 1.8537194760173946e-05, 'num_leaves': 1120, 'feature_fraction': 0.8153806276422135, 'bagging_fraction': 0.7617996267835728, 'bagging_freq': 4, 'learning_rate': 0.16915049536950308}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:53,294]\u001b[0m Trial 40 finished with value: -0.7873770877154145 and parameters: {'lambda_l1': 4.409247622240521e-08, 'lambda_l2': 4.035032846322665e-07, 'num_leaves': 2820, 'feature_fraction': 0.5254593594436583, 'bagging_fraction': 0.5864592598311508, 'bagging_freq': 4, 'learning_rate': 0.06858787631346594}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:56,797]\u001b[0m Trial 41 finished with value: -0.7745298322009609 and parameters: {'lambda_l1': 0.022946236013114005, 'lambda_l2': 1.3776872429743904e-05, 'num_leaves': 1140, 'feature_fraction': 0.8119676755587439, 'bagging_fraction': 0.7771186063476724, 'bagging_freq': 4, 'learning_rate': 0.16949350853090495}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:01:59,611]\u001b[0m Trial 42 finished with value: -0.7682682827928173 and parameters: {'lambda_l1': 0.0045932277249370245, 'lambda_l2': 3.091819685300139e-08, 'num_leaves': 520, 'feature_fraction': 0.7894669900783848, 'bagging_fraction': 0.711505289953233, 'bagging_freq': 4, 'learning_rate': 0.18833370239779199}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:02,942]\u001b[0m Trial 43 finished with value: -0.7719256219252925 and parameters: {'lambda_l1': 0.13063853920821758, 'lambda_l2': 0.00010544562436750013, 'num_leaves': 1540, 'feature_fraction': 0.8436115194010819, 'bagging_fraction': 0.759646185290077, 'bagging_freq': 5, 'learning_rate': 0.21081764757524094}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:06,143]\u001b[0m Trial 44 finished with value: -0.7858972830058185 and parameters: {'lambda_l1': 0.013143656966400723, 'lambda_l2': 2.2263974776515836e-05, 'num_leaves': 1120, 'feature_fraction': 0.880966391501727, 'bagging_fraction': 0.6760429349202717, 'bagging_freq': 3, 'learning_rate': 0.15807567650852142}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:09,983]\u001b[0m Trial 45 finished with value: -0.7753109260021568 and parameters: {'lambda_l1': 9.215466608962465e-05, 'lambda_l2': 0.0005108550517358916, 'num_leaves': 2620, 'feature_fraction': 0.7269242815920252, 'bagging_fraction': 0.8148354316814579, 'bagging_freq': 2, 'learning_rate': 0.1674446487786338}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:11,900]\u001b[0m Trial 46 finished with value: -0.7782682517492551 and parameters: {'lambda_l1': 0.7514539041818208, 'lambda_l2': 0.0016996987418009357, 'num_leaves': 1680, 'feature_fraction': 0.4396901942739967, 'bagging_fraction': 0.8759808314834824, 'bagging_freq': 4, 'learning_rate': 0.2370817099472872}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:16,195]\u001b[0m Trial 47 finished with value: -0.7884050554072659 and parameters: {'lambda_l1': 4.2680579602558753e-07, 'lambda_l2': 9.687523977357258e-07, 'num_leaves': 2000, 'feature_fraction': 0.6963691599367212, 'bagging_fraction': 0.950684102244487, 'bagging_freq': 3, 'learning_rate': 0.19220628202264683}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:20,086]\u001b[0m Trial 48 finished with value: -0.7752954315595282 and parameters: {'lambda_l1': 6.891826765847991e-06, 'lambda_l2': 2.1032270246820053e-06, 'num_leaves': 2860, 'feature_fraction': 0.9497205616394431, 'bagging_fraction': 0.7608011524223185, 'bagging_freq': 7, 'learning_rate': 0.12561324449067032}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:22,806]\u001b[0m Trial 49 finished with value: -0.7747940400949349 and parameters: {'lambda_l1': 0.0006372271438746003, 'lambda_l2': 9.004976983814181, 'num_leaves': 1380, 'feature_fraction': 0.8361901029936496, 'bagging_fraction': 0.6469041363244576, 'bagging_freq': 1, 'learning_rate': 0.09245723805721565}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:24,429]\u001b[0m Trial 50 finished with value: -0.7967988177754237 and parameters: {'lambda_l1': 0.06677165417792694, 'lambda_l2': 0.047101085326202996, 'num_leaves': 700, 'feature_fraction': 0.6066860076484422, 'bagging_fraction': 0.43603708420986764, 'bagging_freq': 6, 'learning_rate': 0.24749891200090507}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:26,718]\u001b[0m Trial 51 finished with value: -0.7651612287203258 and parameters: {'lambda_l1': 0.027774004345386648, 'lambda_l2': 5.128927287071349e-05, 'num_leaves': 1300, 'feature_fraction': 0.821717146748106, 'bagging_fraction': 0.48486120620881323, 'bagging_freq': 2, 'learning_rate': 0.14708010317216066}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:27,363]\u001b[0m Trial 52 finished with value: -0.7710309791893647 and parameters: {'lambda_l1': 0.010742374950866104, 'lambda_l2': 0.00029221039311118135, 'num_leaves': 60, 'feature_fraction': 0.786279156879632, 'bagging_fraction': 0.5039223261900283, 'bagging_freq': 2, 'learning_rate': 0.13976713032294566}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:29,533]\u001b[0m Trial 53 finished with value: -0.7862202969357698 and parameters: {'lambda_l1': 0.00332025673406168, 'lambda_l2': 6.821049020299239e-05, 'num_leaves': 1000, 'feature_fraction': 0.7532046117804302, 'bagging_fraction': 0.47147345548691943, 'bagging_freq': 3, 'learning_rate': 0.17456681258434556}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:32,191]\u001b[0m Trial 54 finished with value: -0.7868887358371051 and parameters: {'lambda_l1': 0.23820581520526135, 'lambda_l2': 1.0207706495171436e-05, 'num_leaves': 1260, 'feature_fraction': 0.9234722090670118, 'bagging_fraction': 0.6093764992324104, 'bagging_freq': 2, 'learning_rate': 0.10668768370375023}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:34,463]\u001b[0m Trial 55 finished with value: -0.775457855249565 and parameters: {'lambda_l1': 0.024392681755157804, 'lambda_l2': 0.0009778516512439232, 'num_leaves': 860, 'feature_fraction': 0.8600742889475864, 'bagging_fraction': 0.5258395291486, 'bagging_freq': 5, 'learning_rate': 0.1646009612906795}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:37,038]\u001b[0m Trial 56 finished with value: -0.7785137615142917 and parameters: {'lambda_l1': 2.7314010339869087e-08, 'lambda_l2': 3.1112643390510766e-05, 'num_leaves': 1440, 'feature_fraction': 0.827676853418768, 'bagging_fraction': 0.5636388872902669, 'bagging_freq': 1, 'learning_rate': 0.12144883140123353}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:38,388]\u001b[0m Trial 57 finished with value: -0.7824789678304461 and parameters: {'lambda_l1': 1.9150387715016484, 'lambda_l2': 1.298211016637745, 'num_leaves': 2900, 'feature_fraction': 0.4792584282733591, 'bagging_fraction': 0.48326388188869585, 'bagging_freq': 2, 'learning_rate': 0.14929076318762124}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:40,771]\u001b[0m Trial 58 finished with value: -0.802049939892927 and parameters: {'lambda_l1': 0.0015445362471252287, 'lambda_l2': 3.636145313746197e-08, 'num_leaves': 2600, 'feature_fraction': 0.7999044196947113, 'bagging_fraction': 0.441274283348383, 'bagging_freq': 3, 'learning_rate': 0.20465401981172973}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:44,569]\u001b[0m Trial 59 finished with value: -0.7866544476303396 and parameters: {'lambda_l1': 5.6991603097473614e-08, 'lambda_l2': 4.991811957825386e-06, 'num_leaves': 1680, 'feature_fraction': 0.6732394918414502, 'bagging_fraction': 0.8592970654651448, 'bagging_freq': 3, 'learning_rate': 0.1358334935767633}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:47,811]\u001b[0m Trial 60 finished with value: -0.7817969359120427 and parameters: {'lambda_l1': 0.0049034381907491495, 'lambda_l2': 2.3334598518836695e-07, 'num_leaves': 1820, 'feature_fraction': 0.7647269110667353, 'bagging_fraction': 0.6886347101534285, 'bagging_freq': 2, 'learning_rate': 0.18559676893774762}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:50,197]\u001b[0m Trial 61 finished with value: -0.7767386843600232 and parameters: {'lambda_l1': 0.040942916448573306, 'lambda_l2': 5.27015987953504e-05, 'num_leaves': 1200, 'feature_fraction': 0.8253041275684825, 'bagging_fraction': 0.5182464353986163, 'bagging_freq': 1, 'learning_rate': 0.14738897032684967}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:52,469]\u001b[0m Trial 62 finished with value: -0.7843802595279133 and parameters: {'lambda_l1': 0.1183588557485935, 'lambda_l2': 0.005376804109160092, 'num_leaves': 1320, 'feature_fraction': 0.8762619170547671, 'bagging_fraction': 0.4976615858815249, 'bagging_freq': 2, 'learning_rate': 0.15525716878635035}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:54,758]\u001b[0m Trial 63 finished with value: -0.7654532909972829 and parameters: {'lambda_l1': 1.089649655206395e-08, 'lambda_l2': 2.2144784967831387e-05, 'num_leaves': 1400, 'feature_fraction': 0.7787725278692478, 'bagging_fraction': 0.48643485868494923, 'bagging_freq': 2, 'learning_rate': 0.2845847746372309}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:56,966]\u001b[0m Trial 64 finished with value: -0.8310855808219779 and parameters: {'lambda_l1': 1.2592347758750464e-07, 'lambda_l2': 0.21711138164430518, 'num_leaves': 3000, 'feature_fraction': 0.7444259850739833, 'bagging_fraction': 0.4221494706600196, 'bagging_freq': 3, 'learning_rate': 0.28922412709512124}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:02:59,091]\u001b[0m Trial 65 finished with value: -0.769037142458552 and parameters: {'lambda_l1': 1.2130465431935289e-08, 'lambda_l2': 1.8331156602453845e-05, 'num_leaves': 1060, 'feature_fraction': 0.7729768390482032, 'bagging_fraction': 0.4579718760861031, 'bagging_freq': 1, 'learning_rate': 0.2696517497013361}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:03:02,068]\u001b[0m Trial 66 finished with value: -0.7929269390696049 and parameters: {'lambda_l1': 9.591785938158434e-08, 'lambda_l2': 0.0001753288188619945, 'num_leaves': 880, 'feature_fraction': 0.42519140350678913, 'bagging_fraction': 0.8046081987374046, 'bagging_freq': 4, 'learning_rate': 0.2588420155893054}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:03:05,398]\u001b[0m Trial 67 finished with value: -0.7590621831865696 and parameters: {'lambda_l1': 2.7909449789313038e-08, 'lambda_l2': 9.022586893099946e-07, 'num_leaves': 2680, 'feature_fraction': 0.6135981291635164, 'bagging_fraction': 0.7290452457179258, 'bagging_freq': 2, 'learning_rate': 0.282607356577248}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:03:09,749]\u001b[0m Trial 68 finished with value: -0.7947556681760961 and parameters: {'lambda_l1': 2.0233305946686103e-08, 'lambda_l2': 7.288363781933587e-08, 'num_leaves': 2780, 'feature_fraction': 0.6164347440463595, 'bagging_fraction': 0.7244823791371183, 'bagging_freq': 2, 'learning_rate': 0.28160555000251103}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:03:12,555]\u001b[0m Trial 69 finished with value: -0.8186849002024478 and parameters: {'lambda_l1': 1.0320238777135317e-08, 'lambda_l2': 7.348068995733118e-07, 'num_leaves': 2260, 'feature_fraction': 0.6304517376224785, 'bagging_fraction': 0.4846927392214985, 'bagging_freq': 2, 'learning_rate': 0.2883904248199261}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:03:15,144]\u001b[0m Trial 70 finished with value: -0.783379990298486 and parameters: {'lambda_l1': 1.5492318190698738e-07, 'lambda_l2': 8.012243972555346e-06, 'num_leaves': 2700, 'feature_fraction': 0.5807322892487589, 'bagging_fraction': 0.42520249927898973, 'bagging_freq': 1, 'learning_rate': 0.2727899493243754}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:03:19,383]\u001b[0m Trial 71 finished with value: -0.7706765307883836 and parameters: {'lambda_l1': 6.107545861521201e-07, 'lambda_l2': 2.8164358433861513e-06, 'num_leaves': 2860, 'feature_fraction': 0.5089583033963042, 'bagging_fraction': 0.7502675446974146, 'bagging_freq': 2, 'learning_rate': 0.2551166439036182}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:03:23,623]\u001b[0m Trial 72 finished with value: -0.7583723504867244 and parameters: {'lambda_l1': 5.615646556945359e-08, 'lambda_l2': 3.933441771590081e-07, 'num_leaves': 2520, 'feature_fraction': 0.5641879488390728, 'bagging_fraction': 0.7947169646468203, 'bagging_freq': 2, 'learning_rate': 0.29719275072584295}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:03:28,727]\u001b[0m Trial 73 finished with value: -0.7639658095388129 and parameters: {'lambda_l1': 7.209510381026985e-08, 'lambda_l2': 1.463644137661998e-06, 'num_leaves': 2700, 'feature_fraction': 0.5611969459383935, 'bagging_fraction': 0.780798145021719, 'bagging_freq': 2, 'learning_rate': 0.2985267473277429}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:03:35,542]\u001b[0m Trial 74 finished with value: -0.7844341061879121 and parameters: {'lambda_l1': 6.305237485545066e-08, 'lambda_l2': 4.414323754149496e-07, 'num_leaves': 2680, 'feature_fraction': 0.5701248705529196, 'bagging_fraction': 0.7848161098296251, 'bagging_freq': 1, 'learning_rate': 0.292011185854104}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:03:43,283]\u001b[0m Trial 75 finished with value: -0.7588511616166169 and parameters: {'lambda_l1': 2.4565758376926676e-07, 'lambda_l2': 1.5127329662601648e-06, 'num_leaves': 2500, 'feature_fraction': 0.5328372261839005, 'bagging_fraction': 0.8313327037902909, 'bagging_freq': 2, 'learning_rate': 0.29511160958479554}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:03:47,351]\u001b[0m Trial 76 finished with value: -0.796255856024716 and parameters: {'lambda_l1': 1.4938722612127966e-06, 'lambda_l2': 2.3507853585174313e-07, 'num_leaves': 2480, 'feature_fraction': 0.5323269557734222, 'bagging_fraction': 0.8275360897331349, 'bagging_freq': 2, 'learning_rate': 0.29683357879687694}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:03:51,251]\u001b[0m Trial 77 finished with value: -0.7794944060206805 and parameters: {'lambda_l1': 2.050684070727569e-07, 'lambda_l2': 1.5193312586044197e-06, 'num_leaves': 2340, 'feature_fraction': 0.5558566246436586, 'bagging_fraction': 0.8495003847512429, 'bagging_freq': 3, 'learning_rate': 0.2734423383139392}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:03:55,510]\u001b[0m Trial 78 finished with value: -0.7784889803862844 and parameters: {'lambda_l1': 3.040087736162585e-07, 'lambda_l2': 7.789622470287432e-08, 'num_leaves': 2540, 'feature_fraction': 0.5851999117402773, 'bagging_fraction': 0.8811228128330174, 'bagging_freq': 2, 'learning_rate': 0.2636404902150318}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:03:59,562]\u001b[0m Trial 79 finished with value: -0.8146103807712923 and parameters: {'lambda_l1': 2.657429197437106e-08, 'lambda_l2': 6.912512901318362e-07, 'num_leaves': 2920, 'feature_fraction': 0.5131993966446083, 'bagging_fraction': 0.8033883559357856, 'bagging_freq': 1, 'learning_rate': 0.2786555875872076}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:04:03,353]\u001b[0m Trial 80 finished with value: -0.7911128198781303 and parameters: {'lambda_l1': 7.311805667791425e-08, 'lambda_l2': 2.480522524644887e-07, 'num_leaves': 2780, 'feature_fraction': 0.47717397362703484, 'bagging_fraction': 0.7404437321099724, 'bagging_freq': 3, 'learning_rate': 0.2997014142483561}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:04:07,567]\u001b[0m Trial 81 finished with value: -0.7915697502295763 and parameters: {'lambda_l1': 4.549923625460454e-08, 'lambda_l2': 1.8687726901056081e-06, 'num_leaves': 2620, 'feature_fraction': 0.5389709976473935, 'bagging_fraction': 0.8200499825475768, 'bagging_freq': 2, 'learning_rate': 0.22694659000557918}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:04:11,455]\u001b[0m Trial 82 finished with value: -0.7727472405514918 and parameters: {'lambda_l1': 1.7238391468410885e-08, 'lambda_l2': 3.6227631648781386e-06, 'num_leaves': 2520, 'feature_fraction': 0.6178503127960623, 'bagging_fraction': 0.772383906591322, 'bagging_freq': 2, 'learning_rate': 0.292126729402981}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:04:15,208]\u001b[0m Trial 83 finished with value: -0.7649740764319992 and parameters: {'lambda_l1': 3.060727619596387e-08, 'lambda_l2': 3.639410806001678, 'num_leaves': 2360, 'feature_fraction': 0.5466301715648423, 'bagging_fraction': 0.7981085054941918, 'bagging_freq': 2, 'learning_rate': 0.2808948906965515}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:04:18,910]\u001b[0m Trial 84 finished with value: -0.7653747945079116 and parameters: {'lambda_l1': 3.251257269829621e-08, 'lambda_l2': 4.707373685940444, 'num_leaves': 2340, 'feature_fraction': 0.5452093299383387, 'bagging_fraction': 0.7959661746000953, 'bagging_freq': 1, 'learning_rate': 0.2644794345601791}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:04:24,830]\u001b[0m Trial 85 finished with value: -0.8034497028552249 and parameters: {'lambda_l1': 2.634927986353032e-07, 'lambda_l2': 3.2972246061633785, 'num_leaves': 2140, 'feature_fraction': 0.4912335558641485, 'bagging_fraction': 0.8419904258508438, 'bagging_freq': 2, 'learning_rate': 0.24512535183784778}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:04:30,124]\u001b[0m Trial 86 finished with value: -0.739968062239208 and parameters: {'lambda_l1': 8.212550702159798e-08, 'lambda_l2': 0.5296907932490675, 'num_leaves': 2400, 'feature_fraction': 0.5683282737266355, 'bagging_fraction': 0.7180695480537155, 'bagging_freq': 3, 'learning_rate': 0.27751509915880435}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:04:37,435]\u001b[0m Trial 87 finished with value: -0.7504119076858646 and parameters: {'lambda_l1': 0.00010540187678791193, 'lambda_l2': 1.9500341998869905e-08, 'num_leaves': 2700, 'feature_fraction': 0.5724703407652546, 'bagging_fraction': 0.7044278878056174, 'bagging_freq': 3, 'learning_rate': 0.2770608034077307}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:04:49,814]\u001b[0m Trial 88 finished with value: -0.7571445653692612 and parameters: {'lambda_l1': 8.682144823551368e-05, 'lambda_l2': 1.2574400159348598e-08, 'num_leaves': 2940, 'feature_fraction': 0.599238708877606, 'bagging_fraction': 0.666805464402468, 'bagging_freq': 3, 'learning_rate': 0.2520759943527358}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:04:56,302]\u001b[0m Trial 89 finished with value: -0.7573533387798068 and parameters: {'lambda_l1': 5.422280215777762e-05, 'lambda_l2': 2.2921864977009453e-08, 'num_leaves': 2840, 'feature_fraction': 0.5942097773191088, 'bagging_fraction': 0.7019079643482012, 'bagging_freq': 3, 'learning_rate': 0.25135965348074424}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:05:01,756]\u001b[0m Trial 90 finished with value: -0.7528352364657747 and parameters: {'lambda_l1': 5.9098434693738405e-05, 'lambda_l2': 2.4015679591652654e-08, 'num_leaves': 2420, 'feature_fraction': 0.5873344402196516, 'bagging_fraction': 0.7160499878472854, 'bagging_freq': 3, 'learning_rate': 0.2532041983135194}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:05:05,754]\u001b[0m Trial 91 finished with value: -0.754746517438841 and parameters: {'lambda_l1': 0.00011499915980078904, 'lambda_l2': 2.143938690418774e-08, 'num_leaves': 2440, 'feature_fraction': 0.5770843304779807, 'bagging_fraction': 0.7000602242970566, 'bagging_freq': 3, 'learning_rate': 0.252882787050698}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:05:10,317]\u001b[0m Trial 92 finished with value: -0.747279564157838 and parameters: {'lambda_l1': 8.479190016423277e-05, 'lambda_l2': 1.629454293489757e-08, 'num_leaves': 2400, 'feature_fraction': 0.580391161515016, 'bagging_fraction': 0.6994551294193005, 'bagging_freq': 3, 'learning_rate': 0.24197726869853428}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:05:13,949]\u001b[0m Trial 93 finished with value: -0.7952976580869329 and parameters: {'lambda_l1': 0.00013402252478721677, 'lambda_l2': 1.8084398857393897e-08, 'num_leaves': 2220, 'feature_fraction': 0.5759723894641005, 'bagging_fraction': 0.662227855121446, 'bagging_freq': 3, 'learning_rate': 0.2418177630017004}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:05:18,378]\u001b[0m Trial 94 finished with value: -0.7732857203672708 and parameters: {'lambda_l1': 4.72777024144317e-05, 'lambda_l2': 2.0924242394554558e-08, 'num_leaves': 2400, 'feature_fraction': 0.5912959426646152, 'bagging_fraction': 0.7003230783955495, 'bagging_freq': 3, 'learning_rate': 0.23220055558636413}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:05:21,627]\u001b[0m Trial 95 finished with value: -0.7813975193790529 and parameters: {'lambda_l1': 8.811076013905915e-06, 'lambda_l2': 1.0569609748388204e-08, 'num_leaves': 2040, 'feature_fraction': 0.6393772888900885, 'bagging_fraction': 0.6905875296947541, 'bagging_freq': 3, 'learning_rate': 0.25224334977609986}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:05:25,031]\u001b[0m Trial 96 finished with value: -0.7768103748566789 and parameters: {'lambda_l1': 4.802334926919357e-05, 'lambda_l2': 5.515058573645575e-08, 'num_leaves': 2820, 'feature_fraction': 0.5942875515346279, 'bagging_fraction': 0.6402296521296589, 'bagging_freq': 3, 'learning_rate': 0.26431958580110815}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:05:28,163]\u001b[0m Trial 97 finished with value: -0.7956601306515754 and parameters: {'lambda_l1': 0.00048710743414365605, 'lambda_l2': 1.9953943924743508e-08, 'num_leaves': 2280, 'feature_fraction': 0.5698758187356272, 'bagging_fraction': 0.7145093366515722, 'bagging_freq': 3, 'learning_rate': 0.21869300760783864}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:05:31,337]\u001b[0m Trial 98 finished with value: -0.7896483310188938 and parameters: {'lambda_l1': 1.3129290201531021e-05, 'lambda_l2': 9.097022309487538e-08, 'num_leaves': 2960, 'feature_fraction': 0.6267416947438934, 'bagging_fraction': 0.6211630404655014, 'bagging_freq': 3, 'learning_rate': 0.2399124946558817}. Best is trial 22 with value: -0.7377752933919968.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:05:34,697]\u001b[0m Trial 99 finished with value: -0.7311851574903518 and parameters: {'lambda_l1': 0.0001441040170678068, 'lambda_l2': 3.6498482941844166e-08, 'num_leaves': 2600, 'feature_fraction': 0.5952838188136965, 'bagging_fraction': 0.6805593472334575, 'bagging_freq': 4, 'learning_rate': 0.23040343049150605}. Best is trial 99 with value: -0.7311851574903518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: -0.7311851574903518\n",
      "  Params: \n",
      "    lambda_l1: 0.0001441040170678068\n",
      "    lambda_l2: 3.6498482941844166e-08\n",
      "    num_leaves: 2600\n",
      "    feature_fraction: 0.5952838188136965\n",
      "    bagging_fraction: 0.6805593472334575\n",
      "    bagging_freq: 4\n",
      "    learning_rate: 0.23040343049150605\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def objective_gbm(trial):\n",
    "    param = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step = 20),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "    }\n",
    "    \n",
    "    gbm = lgb.train(param, lgb_train)\n",
    "    preds = gbm.predict(valX_np_shuffled_normalized_best)\n",
    "    return score_pred(preds, valY_df_shuffled)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective_gbm, n_trials=100)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'lambda_l1': 0.0023077719434512387, 'lambda_l2': 1.7480233081481513e-07, 'num_leaves': 3000, 'feature_fraction': 0.7886485535894862, 'bagging_fraction': 0.46644991789330914, 'bagging_freq': 1, 'learning_rate': 0.2023565800661427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8160\n",
      "[LightGBM] [Info] Number of data points in the train set: 12288, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.069410\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "-0.7311851574903518\n",
      "Prediction saved...\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': \"rmse\",\n",
    "    'lambda_l1': 0.0001441040170678068,\n",
    "    'lambda_l2': 3.6498482941844166e-08, \n",
    "    'num_leaves': 2600, \n",
    "    'feature_fraction': 0.5952838188136965, \n",
    "    'bagging_fraction': 0.6805593472334575, \n",
    "    'bagging_freq': 4, \n",
    "    'learning_rate': 0.23040343049150605\n",
    "}\n",
    "\n",
    "gbm = lgb.train(param, lgb_train)\n",
    "preds = gbm.predict(valX_np_shuffled_normalized_best)\n",
    "print(score_pred(preds, valY_df_shuffled))\n",
    "pred_test_gbm = gbm.predict(testX_np_shuffled_normalized_best)\n",
    "test_submit(pred_test_gbm, \"GBMBestModels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning with linear fully connected models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.fc1 = nn.Linear(input_size, 5)\n",
    "        self.fc3 = nn.Linear(5, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, loss_fn, train_loader, val_loader, epochs=100, device=\"cuda\"):\n",
    "    tr_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}'.format(epoch, training_loss,\n",
    "        valid_loss))\n",
    "        tr_losses.append(training_loss)\n",
    "        val_losses.append(valid_loss)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.15, Validation Loss: 0.09\n",
      "Epoch: 2, Training Loss: 0.08, Validation Loss: 0.07\n",
      "Epoch: 3, Training Loss: 0.07, Validation Loss: 0.07\n",
      "Epoch: 4, Training Loss: 0.07, Validation Loss: 0.07\n",
      "Epoch: 5, Training Loss: 0.07, Validation Loss: 0.07\n",
      "Epoch: 6, Training Loss: 0.07, Validation Loss: 0.07\n",
      "Epoch: 7, Training Loss: 0.07, Validation Loss: 0.07\n",
      "Epoch: 8, Training Loss: 0.07, Validation Loss: 0.07\n",
      "Epoch: 9, Training Loss: 0.07, Validation Loss: 0.07\n",
      "Epoch: 10, Training Loss: 0.07, Validation Loss: 0.07\n"
     ]
    }
   ],
   "source": [
    "model1 = LinearModel(10, 1).to(\"cuda\")\n",
    "optimizer = optim.Adam(model1.parameters(), lr = 0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "train_loop(\n",
    "    model = model1,\n",
    "    optimizer = optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs = 10,\n",
    "    train_loader=train_loader_recent,\n",
    "    val_loader=val_loader_recent,\n",
    ")\n",
    "torch.save(model1.state_dict(), './model_state/model1.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.495178138635222\n",
      "Prediction saved...\n"
     ]
    }
   ],
   "source": [
    "pred_val_DL_Observed= model1(valX[:, :10]).cpu().detach().numpy()\n",
    "print(score_pred(pred_val_DL_Observed, valY_df))\n",
    "pred_test_DL_Observed = model1(testX[:, :10]).cpu().detach().numpy()\n",
    "test_submit(pred_test_DL_Observed, \"DLObserved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Optuna optimizing hyperparemeters in Nearal Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-23 19:11:34,039]\u001b[0m A new study created in memory with name: no-name-d1d31692-315c-4169-b7fb-79a8e3b16229\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:11:46,037]\u001b[0m Trial 0 finished with value: 0.057472936382206775 and parameters: {'n_layers': 5, 'n_units_l0': 121, 'n_units_l1': 86, 'n_units_l2': 124, 'n_units_l3': 12, 'n_units_l4': 90, 'optimizer': 'RMSprop', 'lr': 1.13299743555736e-05}. Best is trial 0 with value: 0.057472936382206775.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:11:50,990]\u001b[0m Trial 1 finished with value: 0.0767719130186985 and parameters: {'n_layers': 1, 'n_units_l0': 52, 'optimizer': 'SGD', 'lr': 9.474337067007181e-05}. Best is trial 0 with value: 0.057472936382206775.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:12:03,532]\u001b[0m Trial 2 finished with value: 0.047331373944568135 and parameters: {'n_layers': 3, 'n_units_l0': 40, 'n_units_l1': 54, 'n_units_l2': 87, 'optimizer': 'Adam', 'lr': 0.0010888945686495194}. Best is trial 2 with value: 0.047331373944568135.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:12:15,025]\u001b[0m Trial 3 finished with value: 0.04545515213006487 and parameters: {'n_layers': 5, 'n_units_l0': 68, 'n_units_l1': 24, 'n_units_l2': 69, 'n_units_l3': 76, 'n_units_l4': 42, 'optimizer': 'RMSprop', 'lr': 0.00010707036113096987}. Best is trial 3 with value: 0.04545515213006487.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:12:20,665]\u001b[0m Trial 4 finished with value: 0.05426521125870446 and parameters: {'n_layers': 1, 'n_units_l0': 77, 'optimizer': 'RMSprop', 'lr': 3.991492799750557e-05}. Best is trial 3 with value: 0.04545515213006487.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:12:32,486]\u001b[0m Trial 5 finished with value: 0.05204486606332163 and parameters: {'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 15, 'n_units_l2': 123, 'n_units_l3': 88, 'n_units_l4': 120, 'optimizer': 'RMSprop', 'lr': 0.0006551578381347693}. Best is trial 3 with value: 0.04545515213006487.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:12:42,881]\u001b[0m Trial 6 finished with value: 0.046484885194028415 and parameters: {'n_layers': 4, 'n_units_l0': 78, 'n_units_l1': 6, 'n_units_l2': 125, 'n_units_l3': 25, 'optimizer': 'RMSprop', 'lr': 0.0013685453527266544}. Best is trial 3 with value: 0.04545515213006487.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:12:43,890]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:12:54,093]\u001b[0m Trial 8 finished with value: 0.043456237918386854 and parameters: {'n_layers': 4, 'n_units_l0': 122, 'n_units_l1': 124, 'n_units_l2': 84, 'n_units_l3': 124, 'optimizer': 'RMSprop', 'lr': 0.00492663735349352}. Best is trial 8 with value: 0.043456237918386854.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:13:04,479]\u001b[0m Trial 9 finished with value: 0.048743225052021444 and parameters: {'n_layers': 4, 'n_units_l0': 96, 'n_units_l1': 74, 'n_units_l2': 63, 'n_units_l3': 17, 'optimizer': 'RMSprop', 'lr': 0.002050231168591182}. Best is trial 8 with value: 0.043456237918386854.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:13:05,089]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:13:15,347]\u001b[0m Trial 11 finished with value: 0.04621910307711611 and parameters: {'n_layers': 4, 'n_units_l0': 97, 'n_units_l1': 128, 'n_units_l2': 67, 'n_units_l3': 125, 'optimizer': 'RMSprop', 'lr': 0.00019000856203376366}. Best is trial 8 with value: 0.043456237918386854.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:13:26,481]\u001b[0m Trial 12 finished with value: 0.04680549927676717 and parameters: {'n_layers': 5, 'n_units_l0': 97, 'n_units_l1': 38, 'n_units_l2': 79, 'n_units_l3': 125, 'n_units_l4': 13, 'optimizer': 'RMSprop', 'lr': 0.000312592102360872}. Best is trial 8 with value: 0.043456237918386854.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:13:27,239]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:13:28,401]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:13:29,698]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:13:38,268]\u001b[0m Trial 16 finished with value: 0.04253951471764594 and parameters: {'n_layers': 3, 'n_units_l0': 79, 'n_units_l1': 51, 'n_units_l2': 48, 'optimizer': 'RMSprop', 'lr': 0.0003678512273700131}. Best is trial 16 with value: 0.04253951471764594.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:13:45,399]\u001b[0m Trial 17 finished with value: 0.041617869903954365 and parameters: {'n_layers': 2, 'n_units_l0': 111, 'n_units_l1': 53, 'optimizer': 'RMSprop', 'lr': 0.0030446841184451215}. Best is trial 17 with value: 0.041617869903954365.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:13:46,123]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:13:54,605]\u001b[0m Trial 19 finished with value: 0.0495881773919488 and parameters: {'n_layers': 2, 'n_units_l0': 87, 'n_units_l1': 50, 'optimizer': 'Adam', 'lr': 0.0020901746457630994}. Best is trial 17 with value: 0.041617869903954365.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:14:02,233]\u001b[0m Trial 20 finished with value: 0.04681025790826728 and parameters: {'n_layers': 2, 'n_units_l0': 110, 'n_units_l1': 61, 'optimizer': 'RMSprop', 'lr': 0.0003737976957442095}. Best is trial 17 with value: 0.041617869903954365.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:14:10,839]\u001b[0m Trial 21 finished with value: 0.045765230160517 and parameters: {'n_layers': 3, 'n_units_l0': 112, 'n_units_l1': 39, 'n_units_l2': 43, 'optimizer': 'RMSprop', 'lr': 0.004773120968850609}. Best is trial 17 with value: 0.041617869903954365.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:14:19,435]\u001b[0m Trial 22 finished with value: 0.04491733037866652 and parameters: {'n_layers': 3, 'n_units_l0': 125, 'n_units_l1': 107, 'n_units_l2': 9, 'optimizer': 'RMSprop', 'lr': 0.004155041048864912}. Best is trial 17 with value: 0.041617869903954365.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:14:26,645]\u001b[0m Trial 23 finished with value: 0.04726921064623942 and parameters: {'n_layers': 2, 'n_units_l0': 85, 'n_units_l1': 67, 'optimizer': 'RMSprop', 'lr': 0.003132614516660693}. Best is trial 17 with value: 0.041617869903954365.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:14:28,409]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:14:34,135]\u001b[0m Trial 25 finished with value: 0.048381367310260735 and parameters: {'n_layers': 1, 'n_units_l0': 114, 'optimizer': 'RMSprop', 'lr': 0.001158759009532118}. Best is trial 17 with value: 0.041617869903954365.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:14:42,758]\u001b[0m Trial 26 finished with value: 0.05025597696658224 and parameters: {'n_layers': 3, 'n_units_l0': 93, 'n_units_l1': 43, 'n_units_l2': 98, 'optimizer': 'RMSprop', 'lr': 0.00282194383386356}. Best is trial 17 with value: 0.041617869903954365.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:14:43,358]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:14:44,606]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:14:45,715]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:14:54,376]\u001b[0m Trial 30 finished with value: 0.04088609882940849 and parameters: {'n_layers': 3, 'n_units_l0': 128, 'n_units_l1': 86, 'n_units_l2': 29, 'optimizer': 'RMSprop', 'lr': 0.0003557540548570621}. Best is trial 30 with value: 0.04088609882940849.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:14:55,246]\u001b[0m Trial 31 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:02,694]\u001b[0m Trial 32 finished with value: 0.04524871594427774 and parameters: {'n_layers': 3, 'n_units_l0': 119, 'n_units_l1': 117, 'n_units_l2': 28, 'optimizer': 'RMSprop', 'lr': 0.00036535446296419186}. Best is trial 30 with value: 0.04088609882940849.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:08,304]\u001b[0m Trial 33 finished with value: 0.04590296318444113 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'optimizer': 'RMSprop', 'lr': 0.00023727120879452873}. Best is trial 30 with value: 0.04088609882940849.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:15,516]\u001b[0m Trial 34 finished with value: 0.047229175843919315 and parameters: {'n_layers': 2, 'n_units_l0': 61, 'n_units_l1': 89, 'optimizer': 'RMSprop', 'lr': 0.0014973923920521385}. Best is trial 30 with value: 0.04088609882940849.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:16,459]\u001b[0m Trial 35 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:17,363]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:17,901]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:21,057]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:22,197]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:23,362]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:24,244]\u001b[0m Trial 41 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:25,155]\u001b[0m Trial 42 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:32,109]\u001b[0m Trial 43 finished with value: 0.046383123573226236 and parameters: {'n_layers': 2, 'n_units_l0': 121, 'n_units_l1': 122, 'optimizer': 'RMSprop', 'lr': 0.0032949092917027097}. Best is trial 30 with value: 0.04088609882940849.\u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:33,156]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:34,079]\u001b[0m Trial 45 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:36,163]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:37,664]\u001b[0m Trial 47 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:38,419]\u001b[0m Trial 48 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-11-23 19:15:39,810]\u001b[0m Trial 49 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  50\n",
      "  Number of pruned trials:  25\n",
      "  Number of complete trials:  25\n",
      "Best trial:\n",
      "  Value:  0.04088609882940849\n",
      "  Params: \n",
      "    n_layers: 3\n",
      "    n_units_l0: 128\n",
      "    n_units_l1: 86\n",
      "    n_units_l2: 29\n",
      "    optimizer: RMSprop\n",
      "    lr: 0.0003557540548570621\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 1\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE*30\n",
    "N_VALID_EXAMPLES = BATCHSIZE*10\n",
    "trainX_best = torch.from_numpy(trainX_np_shuffled_normalized_best).to(\"cuda\").float()\n",
    "valX_best = torch.from_numpy(valX_np_shuffled_normalized_best).to(\"cuda\").float()\n",
    "\n",
    "train_data_best = TensorDataset(trainX_best, trainY)\n",
    "val_data_best = TensorDataset(valX_best, valY)\n",
    "\n",
    "train_loader_best = DataLoader(train_data_best, batch_size = 64, shuffle = True)\n",
    "val_loader_best = DataLoader(val_data_best, batch_size=64, shuffle=True)\n",
    "def define_model(trial):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 32\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 2, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_features = out_features\n",
    "    \n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def objective(trial):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    train_loader = train_loader_best\n",
    "    val_loader = val_loader_best\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log = True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(DEVICE)\n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "        \n",
    "        trial.report(valid_loss, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    return valid_loss\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, timeout=600)\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best trial:\n",
    "  Value:  0.04088609882940849\n",
    "  Params: \n",
    "    n_layers: 3\n",
    "    n_units_l0: 128\n",
    "    n_units_l1: 86\n",
    "    n_units_l2: 29\n",
    "    optimizer: RMSprop\n",
    "    lr: 0.0003557540548570621\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.06, Validation Loss: 0.05\n",
      "Epoch: 2, Training Loss: 0.04, Validation Loss: 0.06\n",
      "Epoch: 3, Training Loss: 0.04, Validation Loss: 0.04\n",
      "Epoch: 4, Training Loss: 0.03, Validation Loss: 0.05\n",
      "Epoch: 5, Training Loss: 0.03, Validation Loss: 0.04\n",
      "Epoch: 6, Training Loss: 0.03, Validation Loss: 0.04\n",
      "Epoch: 7, Training Loss: 0.03, Validation Loss: 0.04\n",
      "Epoch: 8, Training Loss: 0.02, Validation Loss: 0.04\n",
      "Epoch: 9, Training Loss: 0.02, Validation Loss: 0.05\n",
      "Epoch: 10, Training Loss: 0.02, Validation Loss: 0.04\n"
     ]
    }
   ],
   "source": [
    "class LinearOptimized(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearOptimized, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128 , 86)\n",
    "        self.fc3 = nn.Linear(86, 29)\n",
    "        self.fc4 = nn.Linear(29, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "model2 = LinearOptimized(32, 1).to(DEVICE)\n",
    "optimizer2 = optim.RMSprop(model2.parameters(), lr = 0.0003557540548570621)\n",
    "loss_fn = nn.MSELoss()\n",
    "train_loop(\n",
    "    model = model2,\n",
    "    optimizer = optimizer2,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs = 10,\n",
    "    train_loader=train_loader_best,\n",
    "    val_loader=val_loader_best,\n",
    ")\n",
    "torch.save(model2.state_dict(), './model_state/model2.pt')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7889092497712737\n",
      "Prediction saved...\n"
     ]
    }
   ],
   "source": [
    "pred_val_DL_optimized_best = model2(valX_best).cpu().detach().numpy()\n",
    "print(score_pred(pred_val_DL_optimized_best, valY_df_shuffled))\n",
    "\n",
    "testX_best = torch.from_numpy(testX_np_shuffled_normalized_best).to(\"cuda\").float()\n",
    "pred_test_DL_optimized_best = model2(testX_best).cpu().detach().numpy()\n",
    "test_submit(pred_test_DL_optimized_best, \"DLObservedOptimizedWithBestModels\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f95f82eb10b40882bbd9c12427213978cd8e51ac70110e866df26f9af8fdcea4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
